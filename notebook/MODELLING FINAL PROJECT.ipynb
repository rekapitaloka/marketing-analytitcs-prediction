{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# PreProcessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder,RobustScaler,MinMaxScaler\n",
    "import category_encoders as ce\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Splitting Data\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Resampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Modeling, Fitting and Evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_score, roc_auc_score, plot_roc_curve,recall_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "from sklearn import metrics\n",
    "\n",
    "# Boosting\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#feature Selection\n",
    "from sklearn.feature_selection import SelectPercentile, RFE\n",
    "\n",
    "#clustering\n",
    "from scipy.spatial.distance import cdist,pdist\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#saving\n",
    "import joblib\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('marketing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Response</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1826</td>\n",
       "      <td>1970</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>$84,835.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/16/14</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1961</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>$57,091.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6/15/14</td>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10476</td>\n",
       "      <td>1958</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>$67,267.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5/13/14</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1386</td>\n",
       "      <td>1967</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>$32,474.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5/11/14</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5371</td>\n",
       "      <td>1989</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>$21,474.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4/8/14</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>10142</td>\n",
       "      <td>1976</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>$66,476.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3/7/13</td>\n",
       "      <td>99</td>\n",
       "      <td>372</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>5263</td>\n",
       "      <td>1977</td>\n",
       "      <td>2n Cycle</td>\n",
       "      <td>Married</td>\n",
       "      <td>$31,056.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1/22/13</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>22</td>\n",
       "      <td>1976</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>$46,310.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12/3/12</td>\n",
       "      <td>99</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>528</td>\n",
       "      <td>1978</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>$65,819.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11/29/12</td>\n",
       "      <td>99</td>\n",
       "      <td>267</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>4070</td>\n",
       "      <td>1969</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>$94,871.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9/1/12</td>\n",
       "      <td>99</td>\n",
       "      <td>169</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Year_Birth   Education Marital_Status      Income   Kidhome  \\\n",
       "0      1826        1970  Graduation       Divorced  $84,835.00         0   \n",
       "1         1        1961  Graduation         Single  $57,091.00         0   \n",
       "2     10476        1958  Graduation        Married  $67,267.00         0   \n",
       "3      1386        1967  Graduation       Together  $32,474.00         1   \n",
       "4      5371        1989  Graduation         Single  $21,474.00         1   \n",
       "...     ...         ...         ...            ...          ...      ...   \n",
       "2235  10142        1976         PhD       Divorced  $66,476.00         0   \n",
       "2236   5263        1977    2n Cycle        Married  $31,056.00         1   \n",
       "2237     22        1976  Graduation       Divorced  $46,310.00         1   \n",
       "2238    528        1978  Graduation        Married  $65,819.00         0   \n",
       "2239   4070        1969         PhD        Married  $94,871.00         0   \n",
       "\n",
       "      Teenhome Dt_Customer  Recency  MntWines  ...  NumStorePurchases  \\\n",
       "0            0     6/16/14        0       189  ...                  6   \n",
       "1            0     6/15/14        0       464  ...                  7   \n",
       "2            1     5/13/14        0       134  ...                  5   \n",
       "3            1     5/11/14        0        10  ...                  2   \n",
       "4            0      4/8/14        0         6  ...                  2   \n",
       "...        ...         ...      ...       ...  ...                ...   \n",
       "2235         1      3/7/13       99       372  ...                 11   \n",
       "2236         0     1/22/13       99         5  ...                  3   \n",
       "2237         0     12/3/12       99       185  ...                  5   \n",
       "2238         0    11/29/12       99       267  ...                 10   \n",
       "2239         2      9/1/12       99       169  ...                  4   \n",
       "\n",
       "      NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  \\\n",
       "0                     1             0             0             0   \n",
       "1                     5             0             0             0   \n",
       "2                     2             0             0             0   \n",
       "3                     7             0             0             0   \n",
       "4                     7             1             0             0   \n",
       "...                 ...           ...           ...           ...   \n",
       "2235                  4             0             0             0   \n",
       "2236                  8             0             0             0   \n",
       "2237                  8             0             0             0   \n",
       "2238                  3             0             0             0   \n",
       "2239                  7             0             1             1   \n",
       "\n",
       "      AcceptedCmp1  AcceptedCmp2  Response  Complain  Country  \n",
       "0                0             0         1         0       SP  \n",
       "1                0             1         1         0       CA  \n",
       "2                0             0         0         0       US  \n",
       "3                0             0         0         0      AUS  \n",
       "4                0             0         1         0       SP  \n",
       "...            ...           ...       ...       ...      ...  \n",
       "2235             0             0         0         0       US  \n",
       "2236             0             0         0         0       SP  \n",
       "2237             0             0         0         0       SP  \n",
       "2238             0             0         0         0      IND  \n",
       "2239             0             0         1         0       CA  \n",
       "\n",
       "[2240 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID \n",
      " [ 1826     1 10476 ...    22   528  4070] \n",
      "\n",
      "Year_Birth \n",
      " [1970 1961 1958 1967 1989 1954 1947 1979 1959 1981 1969 1977 1960 1966\n",
      " 1976 1965 1956 1975 1971 1986 1972 1974 1990 1987 1984 1968 1955 1983\n",
      " 1973 1978 1952 1962 1964 1982 1963 1957 1980 1945 1949 1948 1953 1946\n",
      " 1985 1992 1944 1951 1988 1950 1994 1993 1991 1893 1996 1995 1899 1943\n",
      " 1941 1940 1900] \n",
      "\n",
      "Education \n",
      " ['Graduation' 'PhD' '2n Cycle' 'Master' 'Basic'] \n",
      "\n",
      "Marital_Status \n",
      " ['Divorced' 'Single' 'Married' 'Together' 'Widow' 'YOLO' 'Alone' 'Absurd'] \n",
      "\n",
      " Income  \n",
      " ['$84,835.00 ' '$57,091.00 ' '$67,267.00 ' ... '$46,310.00 ' '$65,819.00 '\n",
      " '$94,871.00 '] \n",
      "\n",
      "Kidhome \n",
      " [0 1 2] \n",
      "\n",
      "Teenhome \n",
      " [0 1 2] \n",
      "\n",
      "Dt_Customer \n",
      " ['6/16/14' '6/15/14' '5/13/14' '5/11/14' '4/8/14' '3/17/14' '1/29/14'\n",
      " '1/18/14' '1/11/14' '12/27/13' '12/9/13' '12/7/13' '10/16/13' '10/5/13'\n",
      " '9/11/13' '8/1/13' '7/23/13' '7/1/13' '5/28/13' '3/26/13' '3/15/13'\n",
      " '2/12/13' '11/23/12' '10/13/12' '9/14/12' '6/29/14' '5/31/14' '5/30/14'\n",
      " '4/27/14' '4/11/14' '10/29/13' '10/9/13' '5/10/13' '5/9/13' '4/25/13'\n",
      " '4/20/13' '3/30/13' '3/1/13' '2/14/13' '1/11/13' '1/3/13' '12/19/12'\n",
      " '12/15/12' '12/2/12' '9/17/12' '9/11/12' '5/12/14' '4/28/14' '3/29/14'\n",
      " '3/6/14' '3/4/14' '2/4/14' '2/3/14' '1/1/14' '12/12/13' '11/15/13'\n",
      " '9/20/13' '9/5/13' '8/31/13' '7/30/13' '7/27/13' '6/22/13' '1/5/13'\n",
      " '11/21/12' '11/11/12' '9/28/12' '9/27/12' '9/7/12' '8/13/12' '8/11/12'\n",
      " '8/2/12' '6/25/14' '5/28/14' '4/14/14' '3/10/14' '2/27/14' '2/7/14'\n",
      " '1/28/14' '11/17/13' '11/7/13' '10/17/13' '10/13/13' '10/12/13' '9/30/13'\n",
      " '7/3/13' '6/10/13' '5/29/13' '4/29/13' '3/10/13' '1/2/13' '11/2/12'\n",
      " '10/18/12' '10/1/12' '9/3/12' '8/26/12' '5/23/14' '5/17/14' '4/21/14'\n",
      " '3/23/14' '12/16/13' '11/26/13' '11/14/13' '11/6/13' '10/6/13' '9/27/13'\n",
      " '9/18/13' '9/9/13' '7/18/13' '7/8/13' '5/27/13' '3/5/13' '2/20/13'\n",
      " '1/12/13' '12/24/12' '11/19/12' '3/28/14' '2/24/14' '9/2/13' '8/20/13'\n",
      " '6/23/13' '5/5/13' '4/5/13' '1/4/13' '12/27/12' '11/10/12' '10/29/12'\n",
      " '9/22/12' '3/31/14' '3/21/14' '2/9/14' '9/23/13' '6/27/13' '3/28/13'\n",
      " '3/12/13' '1/16/13' '1/8/13' '12/29/12' '12/12/12' '11/25/12' '9/21/12'\n",
      " '9/9/12' '9/5/12' '8/17/12' '6/22/14' '5/1/14' '1/3/14' '10/11/13'\n",
      " '8/13/13' '6/9/13' '5/7/13' '10/2/12' '9/12/12' '3/19/14' '3/3/14'\n",
      " '2/22/14' '1/24/14' '12/4/13' '11/28/13' '11/5/13' '10/3/13' '8/9/13'\n",
      " '8/7/13' '7/17/13' '7/9/13' '6/11/13' '5/17/13' '3/23/13' '2/19/13'\n",
      " '1/19/13' '1/10/13' '1/1/13' '11/12/12' '5/18/14' '3/30/14' '1/30/14'\n",
      " '1/26/14' '1/22/14' '1/15/14' '12/13/13' '8/4/13' '5/1/13' '4/24/13'\n",
      " '4/3/13' '2/3/13' '11/16/12' '8/3/12' '4/18/14' '4/1/14' '3/18/14'\n",
      " '2/10/14' '11/23/13' '11/21/13' '10/2/13' '7/21/13' '6/18/13' '3/24/13'\n",
      " '12/6/12' '11/9/12' '2/14/14' '10/22/13' '10/4/13' '9/21/13' '8/5/13'\n",
      " '7/14/13' '7/4/13' '4/12/13' '4/10/13' '4/8/13' '3/31/13' '3/17/13'\n",
      " '1/21/13' '12/10/12' '9/24/12' '8/6/12' '6/18/14' '4/5/14' '12/21/13'\n",
      " '10/27/13' '10/21/13' '9/19/13' '9/4/13' '6/25/13' '4/27/13' '4/18/13'\n",
      " '12/30/12' '8/22/12' '8/8/12' '6/19/14' '4/20/14' '2/28/14' '12/17/13'\n",
      " '11/25/13' '10/28/13' '8/15/13' '7/5/13' '6/19/13' '6/16/13' '4/22/13'\n",
      " '3/19/13' '2/23/13' '2/15/13' '10/31/12' '10/7/12' '8/9/12' '5/6/14'\n",
      " '4/15/14' '3/5/14' '2/19/14' '9/7/13' '8/6/13' '7/25/13' '4/30/13'\n",
      " '9/10/12' '3/20/14' '9/28/13' '9/24/13' '2/16/13' '11/22/12' '9/18/12'\n",
      " '8/16/12' '6/5/14' '4/13/14' '4/10/14' '4/3/14' '2/12/14' '12/15/13'\n",
      " '10/30/13' '8/26/13' '2/2/13' '1/25/13' '11/17/12' '11/13/12' '11/7/12'\n",
      " '11/1/12' '10/16/12' '5/8/14' '3/2/14' '6/24/13' '6/13/13' '4/23/13'\n",
      " '4/15/13' '1/29/13' '10/30/12' '10/23/12' '4/17/14' '2/25/14' '12/11/13'\n",
      " '10/10/13' '5/20/13' '5/18/13' '4/7/13' '3/3/13' '12/7/12' '11/28/12'\n",
      " '10/27/12' '9/15/12' '6/17/14' '5/29/14' '3/1/14' '2/15/14' '12/23/13'\n",
      " '11/29/13' '10/25/13' '8/17/13' '6/6/13' '3/29/13' '9/23/12' '8/30/12'\n",
      " '8/1/12' '2/8/14' '1/25/14' '11/27/13' '10/19/13' '3/7/13' '2/28/13'\n",
      " '1/17/13' '11/20/12' '11/5/12' '11/3/12' '8/31/12' '8/12/12' '5/15/14'\n",
      " '4/12/14' '4/6/14' '2/6/14' '7/29/13' '6/29/13' '6/17/13' '6/8/13'\n",
      " '5/26/13' '11/8/12' '8/4/12' '4/30/14' '4/7/14' '3/12/14' '4/13/13'\n",
      " '2/13/13' '6/3/14' '3/25/14' '2/17/14' '2/5/14' '1/27/14' '1/14/14'\n",
      " '7/11/13' '6/2/13' '6/1/13' '5/4/13' '3/18/13' '12/3/12' '11/24/12'\n",
      " '10/26/12' '6/20/14' '1/19/14' '1/9/14' '12/29/13' '12/26/13' '12/8/13'\n",
      " '11/20/13' '8/23/13' '8/19/13' '7/24/13' '10/6/12' '8/18/12' '5/7/14'\n",
      " '11/9/13' '8/25/13' '5/16/13' '4/1/13' '3/27/13' '2/8/13' '9/20/12'\n",
      " '5/22/14' '12/30/13' '11/2/13' '8/21/13' '7/12/13' '6/28/13' '6/4/13'\n",
      " '5/31/13' '3/6/13' '2/18/13' '9/26/12' '8/19/12' '5/2/14' '4/29/14'\n",
      " '2/2/14' '1/5/14' '12/5/13' '11/18/13' '9/10/13' '8/3/13' '2/21/13'\n",
      " '2/10/13' '1/31/13' '12/9/12' '9/29/12' '6/9/14' '4/2/14' '3/24/14'\n",
      " '1/23/14' '9/16/13' '9/12/13' '7/15/13' '3/9/13' '2/9/13' '12/14/12'\n",
      " '10/17/12' '6/23/14' '6/12/14' '6/7/14' '4/9/14' '2/13/14' '12/6/13'\n",
      " '10/20/13' '6/20/13' '5/8/13' '3/11/13' '9/6/12' '3/9/14' '2/11/14'\n",
      " '10/8/13' '8/28/13' '7/6/13' '5/30/13' '5/22/13' '4/2/13' '3/20/13'\n",
      " '3/14/13' '1/22/13' '9/8/12' '8/25/12' '8/14/12' '11/19/13' '6/3/13'\n",
      " '12/21/12' '10/10/12' '8/7/12' '12/24/13' '12/14/13' '5/15/13' '5/6/13'\n",
      " '1/7/13' '11/29/12' '4/24/14' '3/8/14' '7/16/13' '2/22/13' '1/20/13'\n",
      " '1/13/13' '12/25/12' '12/11/12' '6/27/14' '3/16/14' '11/3/13' '9/25/13'\n",
      " '9/15/13' '9/1/13' '8/2/13' '8/27/12' '4/4/14' '9/22/13' '12/22/12'\n",
      " '12/16/12' '8/20/12' '1/7/14' '12/1/13' '9/26/13' '2/25/13' '10/24/12'\n",
      " '10/22/12' '7/31/12' '5/19/14' '5/3/14' '4/16/14' '12/31/13' '12/2/13'\n",
      " '7/22/13' '4/21/13' '4/11/13' '3/22/14' '2/6/13' '12/4/12' '11/6/12'\n",
      " '8/28/12' '7/2/13' '10/12/12' '5/16/14' '4/25/14' '11/13/13' '9/6/13'\n",
      " '11/18/12' '10/15/12' '6/14/14' '1/17/14' '2/7/13' '12/20/13' '9/13/13'\n",
      " '1/6/13' '5/26/14' '1/13/14' '8/8/13' '4/6/13' '2/26/14' '5/14/13'\n",
      " '8/24/12' '5/27/14' '2/23/14' '1/10/14' '7/19/13' '3/25/13' '2/11/13'\n",
      " '1/15/13' '12/5/12' '6/13/14' '6/2/14' '11/1/13' '8/16/13' '2/17/13'\n",
      " '2/4/13' '10/19/12' '6/26/14' '10/23/13' '4/14/13' '10/28/12' '10/1/13'\n",
      " '3/8/13' '11/14/12' '1/12/14' '11/4/13' '8/22/13' '6/21/13' '1/23/13'\n",
      " '10/21/12' '10/4/12' '1/31/14' '1/21/14' '12/28/13' '8/11/13' '5/13/13'\n",
      " '9/2/12' '6/24/14' '6/8/14' '5/24/14' '10/18/13' '9/17/13' '8/14/13'\n",
      " '7/20/13' '6/30/13' '5/11/13' '4/16/13' '5/25/14' '5/10/14' '5/4/14'\n",
      " '8/29/13' '3/22/13' '6/4/14' '5/23/13' '2/1/13' '2/16/14' '10/24/13'\n",
      " '3/2/13' '12/18/12' '11/4/12' '6/11/14' '6/14/13' '6/10/14' '5/5/14'\n",
      " '4/19/14' '8/18/13' '2/26/13' '8/30/13' '6/12/13' '5/12/13' '10/9/12'\n",
      " '11/10/13' '8/24/13' '9/4/12' '2/27/13' '1/6/14' '7/7/13' '11/26/12'\n",
      " '8/29/12' '5/2/13' '3/4/13' '1/27/13' '8/23/12' '10/14/13' '12/23/12'\n",
      " '12/1/12' '8/5/12' '8/27/13' '12/17/12' '6/21/14' '3/26/14' '11/22/13'\n",
      " '8/21/12' '4/22/14' '10/26/13' '5/9/14' '4/17/13' '3/21/13' '1/24/13'\n",
      " '12/28/12' '3/13/14' '2/1/14' '10/15/13' '1/14/13' '10/5/12' '7/13/13'\n",
      " '4/23/14' '2/18/14' '11/12/13' '8/12/13' '12/31/12' '6/28/14' '12/3/13'\n",
      " '12/26/12' '7/30/12' '1/2/14' '4/19/13' '1/26/13' '10/14/12' '9/30/12'\n",
      " '3/11/14' '9/14/13' '7/28/13' '5/19/13' '4/28/13' '1/9/13' '10/20/12'\n",
      " '7/31/13' '5/21/13' '9/25/12' '5/3/13' '12/8/12' '3/27/14' '12/18/13'\n",
      " '11/30/13' '8/10/13' '3/16/13' '11/30/12' '3/7/14' '12/19/13' '10/25/12'\n",
      " '12/25/13' '1/4/14' '11/8/13' '11/27/12' '7/26/13' '12/20/12' '10/11/12'\n",
      " '4/26/14' '12/22/13' '6/26/13' '5/24/13' '8/15/12' '12/10/13' '9/19/12'\n",
      " '8/10/12' '6/6/14' '5/25/13' '4/9/13' '9/1/12'] \n",
      "\n",
      "Recency \n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99] \n",
      "\n",
      "MntWines \n",
      " [ 189  464  134   10    6  336  769   78  384  450  140  431    3   16\n",
      "   63   18   53    5  213  275   40  308  266   80  454   27  184  155\n",
      "  423    7  408    1 1285   71 1248  378   12 1200  709   94    4  539\n",
      "   13  670  158  283  496  292   46   34  167  318  522   67   28   58\n",
      "    2  229   14  622  362   38 1074  983  262  739  610   50  650    9\n",
      "  458  520   20  345   22   42  463  260  180   62  421  154  502  145\n",
      "  322 1099  890  863  448  399   85   97   35  315  738  179  381  247\n",
      "  711   30  288  212  173  604  482  531  230   33  784  600  168  493\n",
      "   29  835 1296  760   70   68  325  303  121  561  462  376  341  595\n",
      "   23  530  594  852  194  216  428 1092  559  606   11  588  316  279\n",
      " 1462  546  277  948  664  268  199   73   96  587   56   45    8  508\n",
      "  234  992  125  174 1478 1001  392  388   65  177  577  460  219   31\n",
      "  117  236  120  200  532  297  151  997  797  823  966   37  416  314\n",
      "  342  629  201  964   72  123  159  209  100 1170  387  357  912  625\n",
      "  420  641  712  465   39  514  565  667   66  129  185 1023  338  647\n",
      "  163   19  182  779   32  298  488  817  459  492  558  383 1043  400\n",
      "  691  783   43  777  402  144  840   88   74   26   15  162 1302   47\n",
      "    0  918  172  931  666   24   25  391   81  674  267  224 1239  412\n",
      " 1205  304   76 1004  584  422  269  613  113  261  856  452  658  451\n",
      "  395  688 1035  365  181  331  256  836  233  881  305  778   69   79\n",
      "  344 1184  490 1349  153   84 1000   52  301  519  238  620  572  380\n",
      "  443  252  796  410  507   55  327  397  105 1126  280  108  102  820\n",
      "   86  217  352  240  124  736 1006  580  112  227  290  284  656  953\n",
      "  626  547  795  895  899  178  265  349  848  962  347  426   48 1076\n",
      "   36  733  523 1083   98   99  138  509  527  340  434  208  438 1308\n",
      "   64  673 1050  787  833  605  800  861  161  359  324  370  245  631\n",
      " 1156  398  122  386  379  243  358  258  846  724  770  815  819  479\n",
      "  938  909  156  940   51  141  160  557  196  295  231 1230   91 1060\n",
      "   17  302  728  110  995  704  415  241  135  254  957  293   21  754\n",
      "  822  373 1171  371  801  244  562  707  356  743  235  393  721  896\n",
      "  879  367  693  816  483 1181  491  755  671 1009  972  598  139  702\n",
      "  239  183  771   83  170   59 1063  789  228  512  355  204  556  317\n",
      "  897  187  826  513  313  329  703  571 1218  478 1332 1032  296  635\n",
      "  294  913  731  281  489  551  471  176  534  768  652 1142   41  207\n",
      "  299  525  676  494  353 1253  521  977  603  967  273  425 1394  171\n",
      "  554  191  131 1073  157  226  186 1276  130  614 1288  563   95  210\n",
      "  306  505  758  824  980  526  690  202  792  545  109  382  132  750\n",
      "  223   57  407   90   61   82  220  517  615  480  752  741  456  143\n",
      "  375 1215  106  871  368 1193  441   87  437  965  510  574  332  642\n",
      "  354  390  476  627  165  806  763  205 1003  790 1148  984  941  799\n",
      "  406  128  377  919  198  215 1493 1090  536 1149  586   77  794  774\n",
      "  328  901  866  753 1048  960  888  654  499  576   44  735  548  206\n",
      "  611  713  593 1311 1166 1486  515 1492  533  575  726  445 1259  248\n",
      " 1111  710 1241  529  447  570  867  757  882  291  333  749  203  619\n",
      "  320  311 1103  404  411  211  446  374  221 1047 1206  274  889  146\n",
      " 1115   54  251  166   75  364 1016  432  270  722  516  350  403  218\n",
      "  560  729 1224 1121  503 1245 1459  621  430  979  116  853   93  127\n",
      "  689  686  630  466  910  389 1379  504   60 1067  264  101  581  952\n",
      "  925  457 1017  249  104  111  618 1039  107  225  440 1168   89  255\n",
      "  424  944  908  597  847  543  742  968  708  152  747  958  330  637\n",
      "  418  986  825 1298 1132  746  812 1315  307  860 1396  583  473  553\n",
      "  675 1324  582 1449  829  335  612  175  197  623  544  714  537  285\n",
      "  366 1252  934  518  734 1045  717  830 1020  680  524 1013  864  164\n",
      "  653  369 1012  133  188  811  639  444  372  928  272   92  555  351\n",
      "  263  982  495  312  737  751  346  684  309  115  136  756 1279  538\n",
      "  920  433  192  453  321  169] \n",
      "\n",
      "MntFruits \n",
      " [104   5  11   0  16 130  80  26   4  82  10   6   1   9   2  21 174   7\n",
      "  42  12  22  45 169   3  35  36  51   8  50  37  76  17 107 105  81  53\n",
      "  96  86  32  19 193  63  83  28  49  34  69  40  48  13  20 148  73  23\n",
      " 103  64  61 142  97 117 134  60  25  30 153  58  33  57  14  24  18 106\n",
      "  88 133  99  68  72  38 129  93  74  27 185  15  79 162  71  56 168  98\n",
      "  44 172  54 140 194  91 183 151 197 178 189 102 155 115  77  90 114  39\n",
      "  59 199 154 123 108 137  66  31  43 120  84  29 112  46 160 159  65 111\n",
      " 147 143 161 144  47 181  89  62  41 132  67 138  55 184 122  75  70  85\n",
      " 149 152 100 164 101 126  87  92 166 124 190 131 163 127] \n",
      "\n",
      "MntMeatProducts \n",
      " [ 379   64   59    1   24  411  252   11  102  535   61  441    8   12\n",
      "   57    2    5    3   76   68   23   73  300   37  171  256   80  706\n",
      "   21    9  449  112    6  349  189   17  204  115   33  816  249  179\n",
      "   38  460    4  981   13    7   43  407  257   26   18  140   16  431\n",
      "   22  518  184  309  125   28  653  780  356  154  528  333  559  348\n",
      "   44   20  536  202  132  459   50   45  292  547   30   41   67  322\n",
      "  232  520  215  159  217   69  100  471  469  192  849  560   14  350\n",
      "  444  206  223  380  311  466  751  785  113  291   83  678  786  207\n",
      "   56  273  214  592  503  228  161   88  128   48   86  240   60   96\n",
      "  898   29   99   77  694   81  403   91  218   46   71  422   31  873\n",
      "  111  168   10   89  269  293  282  241   53   19   15   70  172  137\n",
      "  142   40   79  594  278  569  271  170  242  452  456   84  538  732\n",
      "  548  850  259  651  391   90  298 1725  537  697  687   32  622  209\n",
      "   97   35  731  106  804   42  243    0   98  842  253  124  108   25\n",
      "  413  235  230  145  212  238  320  495  319  424   74  109  599  570\n",
      "  410  483   39  565  670  117  103  575  101  501   27  689   58  482\n",
      "  673  167  195  286  733  165  827  590  364   52 1622  104  211   49\n",
      "  711   75  373  216  119  267  279   54  389  177  160  480  812  545\n",
      "  303  144  323  797  194  127  180  134  649  497  352  400  396  107\n",
      "  199  549  399  573  297  558  136   62  522  420  314  186   92  572\n",
      "   63  388  239  915  367   95  157  143  890   72   82  754  372  114\n",
      "  196   36  761  512  835  131  133  499  417  853  555  175  255  625\n",
      "  219  181  164  925  690  509   51  153  120  270  231  562  655  595\n",
      "  141   78  345  151  951  130  514  845  247  288   66   65   47  317\n",
      "  222  601  523  272  193  779  254  376  155  353  152  792  510  860\n",
      "  818  561  631  203   93  929  470  447  201  974  426  753  110  263\n",
      "  617  178  305  708  182  156  250  158  921  234  398  280   85  746\n",
      "  445  613  384  500  385  401  162  118  265  275   34  174  185  274\n",
      "  221  368  123  476  169  704  639  281 1607  550  377  462  597  147\n",
      "  138  432  397  604  375  374  540  505  507  454  224  226  183  815\n",
      "  961  446  546  567  749  553  264  359  287  329  493  607  428  363\n",
      "  843   55  790  899  337   94  614  387  883  294  260  640  530  335\n",
      "  768  554  116  304  685  473  334  129  276  534  425  461  341  568\n",
      "  442  419  332  672  414  935  163  369  266  747  713  740   87  611\n",
      "  591  295  405  724  602  464  756  758  603  248  149  750  188  586\n",
      "  693  490  674  940  606  324  716  408  430  913  717  494  519  735\n",
      "  205  342  237  932  813  654  360  139  409  315  176  135  415  984\n",
      "  612  213  435  122  227  491  629  395  465  742  338  864  968  392\n",
      "  487  121  946  498  421  736  197  936  166  382  450  455  635  233\n",
      "  351  832  801  838  354 1582  757  650  774  208  126  701] \n",
      "\n",
      "MntFishProducts \n",
      " [111   7  15   0  11 240  21  73  80   3   2  13   4  25  65   8  50 106\n",
      " 138  43  97   6  38  30  20 189 224  16 150  32  10 134 193 180 140 137\n",
      "  28  27  19  98 168  63  76  82  39 205  86  52  46  84 172 119  49 229\n",
      "  42  29 116 114  45  17 259 127  33  78 130 145 218  12 110  62  71 247\n",
      "   1  51  91  26  23  69  34  72 124  99 185  89  47 182 160 136  64 175\n",
      " 162 216 142 207  41 101 108 192  55  59  40  31  24 123 166 201  58  90\n",
      " 169 219  37 125  85  77 151 242  95 234 253 258  36 227  93 188 104 128\n",
      "  94  54 141 250 159 121 232 184 120 179 158 153  35 171 112 202  56 173\n",
      "  81 132 164  75 197 210  60  68 199 181 237 129 156 149 167 231 102 220\n",
      " 212 198  67 208 133 103 254 177  44 246 223 146  48 186 225 147  61   5\n",
      " 194 115] \n",
      "\n",
      "MntSweetProducts \n",
      " [189   0   2  32  34  98  13  20  16   4   1   3   7   8  19  30 197  14\n",
      "  89 172  29 160  12   5  28  60  23  35  92 138  10  80  42  21 167  50\n",
      "  75  53   9 178   6  26  25  99 101 123  82  96  68  37  48 176  49  73\n",
      "  69  58  44  62 128 151 133  11 134  36  41 148  15  51  22 262  18  97\n",
      "  54  77  76 121  45  64 142 198  83  55  67 149  24 175 162  17  40 137\n",
      "  71  94 114  38  74  46  43 102  65 141 110 152 263  27  33 112  70  47\n",
      " 115  59  85 126  61 163  91  95  31 120 116 125 144 122  57  56  81 106\n",
      "  88 185 130 107 143  66 105 111 108 179 118  93 103  84 161 147 194  72\n",
      " 192 109 150  86 153 165 187  78 132 191 174  87 196 157 169  39 136 139\n",
      " 100 129 166 173 188 182 156  79  63 195 127 145 146 124 113] \n",
      "\n",
      "MntGoldProds \n",
      " [218  37  30   0  34  43  65   7   5  26   4 102  32 321  22   2  10  23\n",
      "  44   3 197  17  20  29  16 172  14  45  12   6   9 125  27   1  13   8\n",
      "  66 262  11  15  54 129  39  35  21  40  97  67  90  31 145  42  33  62\n",
      "  41  24 143  50  47 109 168  28 150  91  53 128  48 148  80  25  51 191\n",
      " 108 107  69 121 147  57  71  64  63  61  55 181 135 160  56  86 119  19\n",
      " 112 153 130  18  58 133 152  95  83  88 134  38  68  76 140  79  99  52\n",
      " 116 138 166  59 241 157 114 219 231 110 183 205  74  36 177 192 246 127\n",
      " 122  96  49  77 362  72 144 120 141 248  82 196 139  46  93 190  75 174\n",
      " 170 182  78 169 106  60  92 233 146  89 198 176 171 242 111 158 101 124\n",
      " 118 232 227 203  81 142 117 200  84  85 224 207 154 216  70 151  73 132\n",
      "  94 223 137 100 247 163 126 103 149 162 185 204 173 245 195 161  98 131\n",
      " 187 215 159 249 210 180 115 178 229 155 291 199 175 165 123] \n",
      "\n",
      "NumDealsPurchases \n",
      " [ 1  2  3  0  4 12  7  5  6 11  9  8 10 15 13] \n",
      "\n",
      "NumWebPurchases \n",
      " [ 4  7  3  1 10  2  6  5 25  8  9  0 11 27 23] \n",
      "\n",
      "NumCatalogPurchases \n",
      " [ 4  3  2  0  1  7 10  6  8  5  9 11 28 22] \n",
      "\n",
      "NumStorePurchases \n",
      " [ 6  7  5  2  3  9 10  0  8  4 13 12  1 11] \n",
      "\n",
      "NumWebVisitsMonth \n",
      " [ 1  5  2  7  6  4  8  3  9  0 17 13 10 14 19 20] \n",
      "\n",
      "AcceptedCmp3 \n",
      " [0 1] \n",
      "\n",
      "AcceptedCmp4 \n",
      " [0 1] \n",
      "\n",
      "AcceptedCmp5 \n",
      " [0 1] \n",
      "\n",
      "AcceptedCmp1 \n",
      " [0 1] \n",
      "\n",
      "AcceptedCmp2 \n",
      " [0 1] \n",
      "\n",
      "Response \n",
      " [1 0] \n",
      "\n",
      "Complain \n",
      " [0 1] \n",
      "\n",
      "Country \n",
      " ['SP' 'CA' 'US' 'AUS' 'GER' 'IND' 'SA' 'ME'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#unique dari setiap column\n",
    "for i in data.columns:\n",
    "    result = data[i].unique()\n",
    "    print (i,'\\n',result,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleansing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#menambahkan column umur berdasarkan pengurangan thun bergabung dengan tahun lahir\n",
    "data['Dt_Customer']= pd.to_datetime(data['Dt_Customer'])\n",
    "data['Customer_Age'] = data['Dt_Customer'].dt.year - data['Year_Birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merubah tanggal cust bergabung menjadi berapa lama cust telah bergabung \n",
    "todayy = pd.Timestamp('28/2/21') #tanggal perhitungan terakhir\n",
    "data['Dt_Customer'] = (todayy - data['Dt_Customer']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename col income untuk memudahkan dlm pemanggilan dan merubah mjd numeric\n",
    "data.rename(columns={' Income ':'Income'},inplace=True)\n",
    "data['Income']=data['Income'].str.replace('[$,]','').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2449\n",
       "1       2450\n",
       "2       2483\n",
       "3       2485\n",
       "4       2518\n",
       "        ... \n",
       "2235    2915\n",
       "2236    2959\n",
       "2237    3009\n",
       "2238    3013\n",
       "2239    3102\n",
       "Name: Dt_Customer, Length: 2240, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Dt_Customer']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Meringkas Categori dari Marital_Status\n",
    "Single : Single, Widow, Divorced,Alone\n",
    "Together : Married, Together\n",
    "Other : Absurd, YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Marital_Status'] = data['Marital_Status'].replace(['Widow','Divorced','Alone'],'Single')\n",
    "data['Marital_Status'] = data['Marital_Status'].replace(['Married'],'Together')\n",
    "data['Marital_Status'] = data['Marital_Status'].replace(['Absurd','YOLO'],'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Single', 'Together', 'Other'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Marital_Status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Missing Value*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                      0\n",
       "Year_Birth              0\n",
       "Education               0\n",
       "Marital_Status          0\n",
       "Income                 24\n",
       "Kidhome                 0\n",
       "Teenhome                0\n",
       "Dt_Customer             0\n",
       "Recency                 0\n",
       "MntWines                0\n",
       "MntFruits               0\n",
       "MntMeatProducts         0\n",
       "MntFishProducts         0\n",
       "MntSweetProducts        0\n",
       "MntGoldProds            0\n",
       "NumDealsPurchases       0\n",
       "NumWebPurchases         0\n",
       "NumCatalogPurchases     0\n",
       "NumStorePurchases       0\n",
       "NumWebVisitsMonth       0\n",
       "AcceptedCmp3            0\n",
       "AcceptedCmp4            0\n",
       "AcceptedCmp5            0\n",
       "AcceptedCmp1            0\n",
       "AcceptedCmp2            0\n",
       "Response                0\n",
       "Complain                0\n",
       "Country                 0\n",
       "Customer_Age            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pengisian missing value dimasukkan kedalam column transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Outlier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data.quantile(0.25)\n",
    "q3 = data.quantile(0.75)\n",
    "IQR = q3-q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AcceptedCmp1            6.428571\n",
       "AcceptedCmp2            1.339286\n",
       "AcceptedCmp3            7.276786\n",
       "AcceptedCmp4            7.455357\n",
       "AcceptedCmp5            7.276786\n",
       "Complain                0.937500\n",
       "Country                 0.000000\n",
       "Customer_Age            0.133929\n",
       "Dt_Customer             0.000000\n",
       "Education               0.000000\n",
       "ID                      0.000000\n",
       "Income                  0.357143\n",
       "Kidhome                 0.000000\n",
       "Marital_Status          0.000000\n",
       "MntFishProducts         9.955357\n",
       "MntFruits              10.133929\n",
       "MntGoldProds            9.241071\n",
       "MntMeatProducts         7.812500\n",
       "MntSweetProducts       11.071429\n",
       "MntWines                1.562500\n",
       "NumCatalogPurchases     1.026786\n",
       "NumDealsPurchases       3.839286\n",
       "NumStorePurchases       0.000000\n",
       "NumWebPurchases         0.178571\n",
       "NumWebVisitsMonth       0.357143\n",
       "Recency                 0.000000\n",
       "Response               14.910714\n",
       "Teenhome                0.000000\n",
       "Year_Birth              0.133929\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((data < (q1-1.5*IQR)) | (data > (q3+1.5*IQR))).sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terdapat nilai outlier diatas 10% di beberapa column, jadi jika menggunakan scalling maka akan menggunakan Robust Scaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "preprocessing scheme:\n",
    "    one hot : education,marital_status\n",
    "    binary : country\n",
    "    drop : ID,yearbirth,AcceptedCmp3,AcceptedCmp4,AcceptedCmp5,AcceptedCmp1,AcceptedCmp2,Complain,Dt_Customer,ID(karena tdk ada corelasi dengan respon yang ingin mencari Customer baru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   2240 non-null   int64  \n",
      " 1   Year_Birth           2240 non-null   int64  \n",
      " 2   Education            2240 non-null   object \n",
      " 3   Marital_Status       2240 non-null   object \n",
      " 4   Income               2216 non-null   float64\n",
      " 5   Kidhome              2240 non-null   int64  \n",
      " 6   Teenhome             2240 non-null   int64  \n",
      " 7   Dt_Customer          2240 non-null   int64  \n",
      " 8   Recency              2240 non-null   int64  \n",
      " 9   MntWines             2240 non-null   int64  \n",
      " 10  MntFruits            2240 non-null   int64  \n",
      " 11  MntMeatProducts      2240 non-null   int64  \n",
      " 12  MntFishProducts      2240 non-null   int64  \n",
      " 13  MntSweetProducts     2240 non-null   int64  \n",
      " 14  MntGoldProds         2240 non-null   int64  \n",
      " 15  NumDealsPurchases    2240 non-null   int64  \n",
      " 16  NumWebPurchases      2240 non-null   int64  \n",
      " 17  NumCatalogPurchases  2240 non-null   int64  \n",
      " 18  NumStorePurchases    2240 non-null   int64  \n",
      " 19  NumWebVisitsMonth    2240 non-null   int64  \n",
      " 20  AcceptedCmp3         2240 non-null   int64  \n",
      " 21  AcceptedCmp4         2240 non-null   int64  \n",
      " 22  AcceptedCmp5         2240 non-null   int64  \n",
      " 23  AcceptedCmp1         2240 non-null   int64  \n",
      " 24  AcceptedCmp2         2240 non-null   int64  \n",
      " 25  Response             2240 non-null   int64  \n",
      " 26  Complain             2240 non-null   int64  \n",
      " 27  Country              2240 non-null   object \n",
      " 28  Customer_Age         2240 non-null   int64  \n",
      "dtypes: float64(1), int64(25), object(3)\n",
      "memory usage: 507.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scale = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy = 'mean')),\n",
    "    ('scaling', RobustScaler()),\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('impute',mean_scale,['Income']),\n",
    "    ('encoder',OneHotEncoder(handle_unknown='ignore'),['Education','Marital_Status']),\n",
    "    ('binary',ce.BinaryEncoder(),['Country']),\n",
    "    ('scale',RobustScaler(),['Customer_Age','Recency'])\n",
    "],remainder='passthrough')\n",
    "\n",
    "data=data.drop(['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds','NumDealsPurchases','NumWebPurchases','NumCatalogPurchases','NumStorePurchases','NumWebVisitsMonth','Complain','Dt_Customer','ID','Year_Birth','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5','AcceptedCmp1','AcceptedCmp2'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Education       2240 non-null   object \n",
      " 1   Marital_Status  2240 non-null   object \n",
      " 2   Income          2216 non-null   float64\n",
      " 3   Kidhome         2240 non-null   int64  \n",
      " 4   Teenhome        2240 non-null   int64  \n",
      " 5   Recency         2240 non-null   int64  \n",
      " 6   Response        2240 non-null   int64  \n",
      " 7   Country         2240 non-null   object \n",
      " 8   Customer_Age    2240 non-null   int64  \n",
      "dtypes: float64(1), int64(5), object(3)\n",
      "memory usage: 157.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['Response'],axis=1)\n",
    "y=data['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0104577 ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.16333852,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.47404659,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.16584226,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.4298342 ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.31689109,  0.        ,  0.        , ...,  0.        ,\n",
       "         2.        ,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cek transform\n",
    "transformer.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2240, 8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,stratify=y,test_size=0.3,random_state=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Company ingin melakukan Campaign dengan tujuan menarik konsumen yang belum menjadi member/Customer tetap. Dengan meningkatnya jumlah customer member maka akan memudahkan company dalam hal branding serta evaluasi berdasarkan saran-saran dari customer. Campaign yang dilakukan berdasarkan dengan metode campaign terakhir yang memiliki kesuksesan dibandingkan campaign sebelumnya. dan Respon konsumen akan di prediksi berdasarkan profil serta kapan terakhir konsumen tersebut membeli product kita(Recency, jika blm pernah beli maka (-1))\n",
    "\n",
    "*Customer = Konsumen yang telah menjadi member*\n",
    "\n",
    "* *0 = No respon*\n",
    "* *1 = yes*\n",
    "\n",
    "        - TN: Konsumen yang diprediksi tidak akan merespon campaign, actualnya memang tidak merespon\n",
    "        - TP: Konsumen yang diprediksi akan merespon campaign, actualnya memang merespon\n",
    "        - FP: Konsumen yang diprediksi akan merespon campaign, actualnya tidak merespon\n",
    "        - FN: Konsumen yang diprediksi tidak merespon campaign, actualnya merespon\n",
    "\n",
    "2 Kesalahan yang terjadi:\n",
    "* FN: Salah prediksi, company hanya kehilangan calon customer, tetapi tidak rugi financial\n",
    "* FP: company lebih rugi waktu, tenaga dan financial, karena telah menyiapkan segala sesuatu untuk campaign ke orang tsb, namun ternyata tidak ada respon.\n",
    "\n",
    "**Jadi kesalahan yang paling berpengaruh untuk kerugian financial adalah FP**\n",
    "\n",
    "**Metric evaluasi yang dipilih adalah Precision karena akan menekan nilai FP, Nilai FP dan Precision berbanding terbalik**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model BenchMark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Cek Balancing Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85.089286\n",
       "1    14.910714\n",
       "Name: Response, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Response'].value_counts()/data.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data imbalance, jd ketika nilai masih rendah bisa dilkukan balancing untuk memilih model terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "tree = DecisionTreeClassifier(random_state = 2020)\n",
    "knn = KNeighborsClassifier()\n",
    "rf = RandomForestClassifier(random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe = Pipeline([\n",
    "    ('transform',transformer),\n",
    "    ('logreg',logreg)\n",
    "])\n",
    "\n",
    "tree_pipe= Pipeline([\n",
    "    ('transform',transformer),\n",
    "    ('tree',tree)\n",
    "])\n",
    "\n",
    "knn_pipe =Pipeline([\n",
    "    ('transform',transformer),\n",
    "    ('knn',knn)\n",
    "])\n",
    "\n",
    "rf_pipe = Pipeline([\n",
    "    ('transform',transformer),\n",
    "    ('rf',rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean score</th>\n",
       "      <th>std score</th>\n",
       "      <th>precision score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.528766</td>\n",
       "      <td>0.199787</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.252752</td>\n",
       "      <td>0.064072</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.369554</td>\n",
       "      <td>0.057294</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.513016</td>\n",
       "      <td>0.090920</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     method  mean score  std score  precision score\n",
       "0       Logistic Regression    0.528766   0.199787         0.823529\n",
       "1  Decision Tree Classifier    0.252752   0.064072         0.407407\n",
       "2            KNN Classifier    0.369554   0.057294         0.466667\n",
       "3  Random Forest Classifier    0.513016   0.090920         0.724138"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_evaluation(model, metric):\n",
    "    skfold = StratifiedKFold(n_splits = 5)\n",
    "    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric)\n",
    "    return model_cv\n",
    "\n",
    "logreg_pipe_cv = model_evaluation(logreg_pipe, 'precision')\n",
    "tree_pipe_cv = model_evaluation(tree_pipe, 'precision')\n",
    "knn_pipe_cv = model_evaluation(knn_pipe, 'precision')\n",
    "rf_pipe_cv = model_evaluation(rf_pipe, 'precision')\n",
    "\n",
    "for model in [logreg_pipe,tree_pipe, knn_pipe,rf_pipe]:\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "score_mean = [logreg_pipe_cv.mean(),tree_pipe_cv.mean(),knn_pipe_cv.mean(),rf_pipe_cv.mean()]\n",
    "score_std = [logreg_pipe_cv.std(),tree_pipe_cv.std(),knn_pipe_cv.std(),rf_pipe_cv.std()]\n",
    "score_precision_score = [precision_score(y_test, logreg_pipe.predict(X_test)),\n",
    "            precision_score(y_test, tree_pipe.predict(X_test)),\n",
    "            precision_score(y_test, knn_pipe.predict(X_test)),\n",
    "            precision_score(y_test, rf_pipe.predict(X_test))]\n",
    "method_name = ['Logistic Regression','Decision Tree Classifier','KNN Classifier', 'Random Forest Classifier']\n",
    "cv_result = pd.DataFrame({\n",
    "    'method': method_name,\n",
    "    'mean score': score_mean,\n",
    "    'std score': score_std,\n",
    "    'precision score': score_precision_score\n",
    "})\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       572\n",
      "           1       0.82      0.14      0.24       100\n",
      "\n",
      "    accuracy                           0.87       672\n",
      "   macro avg       0.85      0.57      0.58       672\n",
      "weighted avg       0.86      0.87      0.83       672\n",
      "\n",
      "[[569   3]\n",
      " [ 86  14]]\n"
     ]
    }
   ],
   "source": [
    "#cek confusion matrix dr model terbaik\n",
    "logreg_pipe.fit(X_train, y_train)\n",
    "ypred=logreg_pipe.predict(X_test)\n",
    "print(classification_report(y_test,ypred))\n",
    "print(metrics.confusion_matrix(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nilai Precision dan meanscore terbaik pada model Logistic Regression, namun akan dicoba untuk Handling Imbalance terlebih dahulu untuk mendapatkan model dengan nilai stabil**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Handling Imbalance Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random Under Sampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state = 2020)\n",
    "X_under, y_under = rus.fit_resample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe_under = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('rus', rus),\n",
    "    ('logreg', logreg)\n",
    "])\n",
    "\n",
    "tree_pipe_under = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('rus', rus),\n",
    "    ('tree', tree)\n",
    "])\n",
    "\n",
    "knn_pipe_under = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('rus', rus),\n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "rf_pipe_under = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('rus', rus),\n",
    "    ('rf', rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean score</th>\n",
       "      <th>std score</th>\n",
       "      <th>precision score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression UnderSampling</td>\n",
       "      <td>0.266582</td>\n",
       "      <td>0.015287</td>\n",
       "      <td>0.286996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier UnderSampling</td>\n",
       "      <td>0.219884</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.212329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Classifier UnderSampling</td>\n",
       "      <td>0.232455</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.214035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier UnderSampling</td>\n",
       "      <td>0.256854</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.283465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   method  mean score  std score  \\\n",
       "0       Logistic Regression UnderSampling    0.266582   0.015287   \n",
       "1  Decision Tree Classifier UnderSampling    0.219884   0.022217   \n",
       "2            KNN Classifier UnderSampling    0.232455   0.014492   \n",
       "3  Random Forest Classifier UnderSampling    0.256854   0.024250   \n",
       "\n",
       "   precision score  \n",
       "0         0.286996  \n",
       "1         0.212329  \n",
       "2         0.214035  \n",
       "3         0.283465  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_evaluation(model, metric):\n",
    "    skfold = StratifiedKFold(n_splits = 5)\n",
    "    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric) \n",
    "    return model_cv\n",
    "\n",
    "logreg_under_cv = model_evaluation(logreg_pipe_under, 'precision') \n",
    "tree_under_cv = model_evaluation(tree_pipe_under, 'precision')\n",
    "knn_under_cv = model_evaluation(knn_pipe_under, 'precision')\n",
    "rf_under_cv = model_evaluation(rf_pipe_under, 'precision')\n",
    "\n",
    "for model in [logreg_pipe_under, tree_pipe_under, knn_pipe_under, rf_pipe_under]:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "score_mean = [logreg_under_cv.mean(), tree_under_cv.mean(), knn_under_cv.mean(),\n",
    "              rf_under_cv.mean()]\n",
    "score_std = [logreg_under_cv.std(), tree_under_cv.std(), knn_under_cv.std(),\n",
    "             rf_under_cv.std()]\n",
    "score_precision_score = [precision_score(y_test, logreg_pipe_under.predict(X_test)),\n",
    "            precision_score(y_test, tree_pipe_under.predict(X_test)), \n",
    "            precision_score(y_test, knn_pipe_under.predict(X_test)), \n",
    "            precision_score(y_test, rf_pipe_under.predict(X_test))]\n",
    "method_name = ['Logistic Regression UnderSampling', 'Decision Tree Classifier UnderSampling',\n",
    "              'KNN Classifier UnderSampling', 'Random Forest Classifier UnderSampling']\n",
    "under_result = pd.DataFrame({\n",
    "    'method': method_name,\n",
    "    'mean score': score_mean,\n",
    "    'std score': score_std,\n",
    "    'precision score': score_precision_score\n",
    "})\n",
    "under_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81       572\n",
      "           1       0.29      0.64      0.40       100\n",
      "\n",
      "    accuracy                           0.71       672\n",
      "   macro avg       0.60      0.68      0.60       672\n",
      "weighted avg       0.83      0.71      0.75       672\n",
      "\n",
      "[[413 159]\n",
      " [ 36  64]]\n"
     ]
    }
   ],
   "source": [
    "#cek confusion matrix dr model terbaik\n",
    "logreg_pipe_under.fit(X_train, y_train)\n",
    "ypred=logreg_pipe_under.predict(X_test)\n",
    "print(classification_report(y_test,ypred))\n",
    "print(metrics.confusion_matrix(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Random Over Sampling*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state = 2020)\n",
    "X_over, y_over = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe_over = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('ros', ros), \n",
    "    ('logreg', logreg)\n",
    "])\n",
    "\n",
    "tree_pipe_over = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('ros', ros), \n",
    "    ('tree', tree)\n",
    "])\n",
    "\n",
    "knn_pipe_over = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('ros', ros), \n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "rf_pipe_over = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('ros', ros),\n",
    "    ('rf', rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean score</th>\n",
       "      <th>std score</th>\n",
       "      <th>precision score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression OverSampling</td>\n",
       "      <td>0.274843</td>\n",
       "      <td>0.026533</td>\n",
       "      <td>0.296804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier OverSampling</td>\n",
       "      <td>0.322504</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>0.387755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Classifier OverSampling</td>\n",
       "      <td>0.212357</td>\n",
       "      <td>0.014576</td>\n",
       "      <td>0.237209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier OverSampling</td>\n",
       "      <td>0.431780</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  method  mean score  std score  \\\n",
       "0       Logistic Regression OverSampling    0.274843   0.026533   \n",
       "1  Decision Tree Classifier OverSampling    0.322504   0.046616   \n",
       "2            KNN Classifier OverSampling    0.212357   0.014576   \n",
       "3  Random Forest Classifier OverSampling    0.431780   0.025124   \n",
       "\n",
       "   precision score  \n",
       "0         0.296804  \n",
       "1         0.387755  \n",
       "2         0.237209  \n",
       "3         0.500000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_evaluation(model, metric):\n",
    "    skfold = StratifiedKFold(n_splits = 5)\n",
    "    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric)\n",
    "    return model_cv\n",
    "\n",
    "logreg_over_cv = model_evaluation(logreg_pipe_over, 'precision') \n",
    "tree_over_cv = model_evaluation(tree_pipe_over, 'precision')\n",
    "knn_over_cv = model_evaluation(knn_pipe_over, 'precision')\n",
    "rf_over_cv = model_evaluation(rf_pipe_over, 'precision')\n",
    "\n",
    "for model in [logreg_pipe_over, tree_pipe_over, knn_pipe_over, rf_pipe_over]:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "score_mean = [logreg_over_cv.mean(), tree_over_cv.mean(), knn_over_cv.mean(),\n",
    "              rf_over_cv.mean()]\n",
    "score_std = [logreg_over_cv.std(), tree_over_cv.std(), knn_over_cv.std(),\n",
    "             rf_over_cv.std()]\n",
    "score_precision_score = [precision_score(y_test, logreg_pipe_over.predict(X_test)),\n",
    "            precision_score(y_test, tree_pipe_over.predict(X_test)), \n",
    "            precision_score(y_test, knn_pipe_over.predict(X_test)), \n",
    "            precision_score(y_test, rf_pipe_over.predict(X_test))]\n",
    "method_name = ['Logistic Regression OverSampling', 'Decision Tree Classifier OverSampling',\n",
    "              'KNN Classifier OverSampling', 'Random Forest Classifier OverSampling']\n",
    "over_summary = pd.DataFrame({\n",
    "    'method': method_name,\n",
    "    'mean score': score_mean,\n",
    "    'std score': score_std,\n",
    "    'precision score': score_precision_score\n",
    "})\n",
    "over_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92       572\n",
      "           1       0.50      0.29      0.37       100\n",
      "\n",
      "    accuracy                           0.85       672\n",
      "   macro avg       0.69      0.62      0.64       672\n",
      "weighted avg       0.83      0.85      0.83       672\n",
      "\n",
      "[[543  29]\n",
      " [ 71  29]]\n"
     ]
    }
   ],
   "source": [
    "#cek confusion matrix dr model terbaik\n",
    "rf_pipe_over.fit(X_train, y_train)\n",
    "ypred=rf_pipe_over.predict(X_test)\n",
    "print(classification_report(y_test,ypred))\n",
    "print(metrics.confusion_matrix(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NearMiss*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm = NearMiss(version = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_pipe_nm = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('nm', nm),\n",
    "    ('logreg', logreg)\n",
    "])\n",
    "\n",
    "tree_pipe_nm = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('nm', nm),\n",
    "    ('tree', tree)\n",
    "])\n",
    "\n",
    "knn_pipe_nm = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('nm', nm),\n",
    "    ('knn', knn)\n",
    "])\n",
    "\n",
    "rf_pipe_nm = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('nm', nm),\n",
    "    ('rf', rf)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean score</th>\n",
       "      <th>std score</th>\n",
       "      <th>precision score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression NearMiss</td>\n",
       "      <td>0.179701</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.163978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier NearMiss</td>\n",
       "      <td>0.165203</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.179348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Classifier NearMiss</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.202429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier NearMiss</td>\n",
       "      <td>0.175692</td>\n",
       "      <td>0.015804</td>\n",
       "      <td>0.176179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              method  mean score  std score  precision score\n",
       "0       Logistic Regression NearMiss    0.179701   0.019814         0.163978\n",
       "1  Decision Tree Classifier NearMiss    0.165203   0.012071         0.179348\n",
       "2            KNN Classifier NearMiss    0.196628   0.014884         0.202429\n",
       "3  Random Forest Classifier NearMiss    0.175692   0.015804         0.176179"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_evaluation(model, metric):\n",
    "    skfold = StratifiedKFold(n_splits = 5)\n",
    "    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric)\n",
    "    return model_cv\n",
    "\n",
    "logreg_nm_cv = model_evaluation(logreg_pipe_nm, 'precision') \n",
    "tree_nm_cv = model_evaluation(tree_pipe_nm, 'precision')\n",
    "knn_nm_cv = model_evaluation(knn_pipe_nm, 'precision')\n",
    "rf_nm_cv = model_evaluation(rf_pipe_nm, 'precision')\n",
    "\n",
    "for model in [logreg_pipe_nm, tree_pipe_nm, knn_pipe_nm, rf_pipe_nm]:\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "score_mean = [logreg_nm_cv.mean(), tree_nm_cv.mean(), knn_nm_cv.mean(),\n",
    "              rf_nm_cv.mean()]\n",
    "score_std = [logreg_nm_cv.std(), tree_nm_cv.std(), knn_nm_cv.std(),\n",
    "             rf_nm_cv.std()]\n",
    "score_precision_score = [precision_score(y_test, logreg_pipe_nm.predict(X_test)),\n",
    "            precision_score(y_test, tree_pipe_nm.predict(X_test)), \n",
    "            precision_score(y_test, knn_pipe_nm.predict(X_test)), \n",
    "            precision_score(y_test, rf_pipe_nm.predict(X_test))]\n",
    "method_name = ['Logistic Regression NearMiss', 'Decision Tree Classifier NearMiss',\n",
    "              'KNN Classifier NearMiss', 'Random Forest Classifier NearMiss']\n",
    "nm_summary = pd.DataFrame({\n",
    "    'method': method_name,\n",
    "    'mean score': score_mean,\n",
    "    'std score': score_std,\n",
    "    'precision score': score_precision_score\n",
    "})\n",
    "nm_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.66      0.75       572\n",
      "           1       0.20      0.50      0.29       100\n",
      "\n",
      "    accuracy                           0.63       672\n",
      "   macro avg       0.54      0.58      0.52       672\n",
      "weighted avg       0.78      0.63      0.68       672\n",
      "\n",
      "[[375 197]\n",
      " [ 50  50]]\n"
     ]
    }
   ],
   "source": [
    "#cek confusion matrix dr model terbaik\n",
    "knn_pipe_nm.fit(X_train, y_train)\n",
    "ypred=knn_pipe_nm.predict(X_test)\n",
    "print(classification_report(y_test,ypred))\n",
    "print(metrics.confusion_matrix(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean score</th>\n",
       "      <th>std score</th>\n",
       "      <th>precision score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression UnderSampling</td>\n",
       "      <td>0.266582</td>\n",
       "      <td>0.015287</td>\n",
       "      <td>0.286996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier UnderSampling</td>\n",
       "      <td>0.219884</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.212329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Classifier UnderSampling</td>\n",
       "      <td>0.232455</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.214035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier UnderSampling</td>\n",
       "      <td>0.256854</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.283465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression OverSampling</td>\n",
       "      <td>0.274843</td>\n",
       "      <td>0.026533</td>\n",
       "      <td>0.296804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier OverSampling</td>\n",
       "      <td>0.322504</td>\n",
       "      <td>0.046616</td>\n",
       "      <td>0.387755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Classifier OverSampling</td>\n",
       "      <td>0.212357</td>\n",
       "      <td>0.014576</td>\n",
       "      <td>0.237209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier OverSampling</td>\n",
       "      <td>0.431780</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression NearMiss</td>\n",
       "      <td>0.179701</td>\n",
       "      <td>0.019814</td>\n",
       "      <td>0.163978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier NearMiss</td>\n",
       "      <td>0.165203</td>\n",
       "      <td>0.012071</td>\n",
       "      <td>0.179348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Classifier NearMiss</td>\n",
       "      <td>0.196628</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.202429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier NearMiss</td>\n",
       "      <td>0.175692</td>\n",
       "      <td>0.015804</td>\n",
       "      <td>0.176179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   method  mean score  std score  \\\n",
       "0       Logistic Regression UnderSampling    0.266582   0.015287   \n",
       "1  Decision Tree Classifier UnderSampling    0.219884   0.022217   \n",
       "2            KNN Classifier UnderSampling    0.232455   0.014492   \n",
       "3  Random Forest Classifier UnderSampling    0.256854   0.024250   \n",
       "0        Logistic Regression OverSampling    0.274843   0.026533   \n",
       "1   Decision Tree Classifier OverSampling    0.322504   0.046616   \n",
       "2             KNN Classifier OverSampling    0.212357   0.014576   \n",
       "3   Random Forest Classifier OverSampling    0.431780   0.025124   \n",
       "0            Logistic Regression NearMiss    0.179701   0.019814   \n",
       "1       Decision Tree Classifier NearMiss    0.165203   0.012071   \n",
       "2                 KNN Classifier NearMiss    0.196628   0.014884   \n",
       "3       Random Forest Classifier NearMiss    0.175692   0.015804   \n",
       "\n",
       "   precision score  \n",
       "0         0.286996  \n",
       "1         0.212329  \n",
       "2         0.214035  \n",
       "3         0.283465  \n",
       "0         0.296804  \n",
       "1         0.387755  \n",
       "2         0.237209  \n",
       "3         0.500000  \n",
       "0         0.163978  \n",
       "1         0.179348  \n",
       "2         0.202429  \n",
       "3         0.176179  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary Balancing Dataset\n",
    "resume_balancing = pd.concat([under_result,over_summary,nm_summary], axis=0)\n",
    "resume_balancing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**setelah dilakukan balancing dataset ternyata nilai precision dan accuracy turun, dan Nilai precicion antara kelas 1 & 0 yang balance ada di model tanpa balancing dataset, sehingga digunakan model tanpa balancing dataset.Dan berdasarkan resume diatas model yang stabil adalah KNN dan Logistic regression. kemudian akan mencoba model Boosting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BOOSTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(\n",
    "            tree,\n",
    "            n_estimators = 50,\n",
    "            learning_rate = 0.1,\n",
    "            random_state = 2020)\n",
    "\n",
    "pipe_ada = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('adaboost', adaboost)\n",
    "])\n",
    "\n",
    "gradboost = GradientBoostingClassifier(\n",
    "            n_estimators = 50,\n",
    "            learning_rate = 0.1,\n",
    "            max_depth = 3,\n",
    "            random_state = 2020)\n",
    "\n",
    "pipe_grad = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('gradboost', gradboost)\n",
    "])\n",
    "\n",
    "XGBOOST = XGBClassifier(\n",
    "            n_estimators = 50,\n",
    "            learning_rate = 0.1,\n",
    "            max_depth = 3,\n",
    "            random_state = 2020)\n",
    "\n",
    "pipe_XGB = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('XGBOOST', XGBOOST)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:15:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean score</th>\n",
       "      <th>std score</th>\n",
       "      <th>precision score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.320199</td>\n",
       "      <td>0.057693</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boost Classifier</td>\n",
       "      <td>0.542337</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>0.554471</td>\n",
       "      <td>0.125104</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      method  mean score  std score  precision score\n",
       "0       Ada Boost Classifier    0.320199   0.057693         0.363636\n",
       "1  Gradient Boost Classifier    0.542337   0.126316         0.714286\n",
       "2             XGB Classifier    0.554471   0.125104         0.772727"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_evaluation(model, metric):\n",
    "    skfold = StratifiedKFold(n_splits = 5)\n",
    "    model_cv = cross_val_score(model, X_train, y_train, cv = skfold, scoring = metric, n_jobs = -1)\n",
    "    return model_cv\n",
    "\n",
    "pipe_ada_cv = model_evaluation(pipe_ada, 'precision')\n",
    "pipe_grad_cv = model_evaluation(pipe_grad, 'precision')\n",
    "pipe_XGB_cv = model_evaluation(pipe_XGB, 'precision')\n",
    "\n",
    "for model in [pipe_ada, pipe_grad, pipe_XGB]:\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "score_mean = [pipe_ada_cv.mean(), pipe_grad_cv.mean(), pipe_XGB_cv.mean()]\n",
    "score_std = [pipe_ada_cv.std(), pipe_grad_cv.std(), pipe_XGB_cv.std()]\n",
    "score_precision_score = [precision_score(y_test, pipe_ada.predict(X_test)),\n",
    "            precision_score(y_test, pipe_grad.predict(X_test)), \n",
    "            precision_score(y_test, pipe_XGB.predict(X_test))]\n",
    "method_name = ['Ada Boost Classifier', 'Gradient Boost Classifier',\n",
    "              'XGB Classifier']\n",
    "boost_summary = pd.DataFrame({\n",
    "    'method': method_name,\n",
    "    'mean score': score_mean,\n",
    "    'std score': score_std,\n",
    "    'precision score': score_precision_score\n",
    "})\n",
    "boost_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>mean score</th>\n",
       "      <th>std score</th>\n",
       "      <th>precision score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.528766</td>\n",
       "      <td>0.199787</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>0.252752</td>\n",
       "      <td>0.064072</td>\n",
       "      <td>0.407407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN Classifier</td>\n",
       "      <td>0.369554</td>\n",
       "      <td>0.057294</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.513016</td>\n",
       "      <td>0.090920</td>\n",
       "      <td>0.724138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada Boost Classifier</td>\n",
       "      <td>0.320199</td>\n",
       "      <td>0.057693</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boost Classifier</td>\n",
       "      <td>0.542337</td>\n",
       "      <td>0.126316</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>0.554471</td>\n",
       "      <td>0.125104</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      method  mean score  std score  precision score\n",
       "0        Logistic Regression    0.528766   0.199787         0.823529\n",
       "1   Decision Tree Classifier    0.252752   0.064072         0.407407\n",
       "2             KNN Classifier    0.369554   0.057294         0.466667\n",
       "3   Random Forest Classifier    0.513016   0.090920         0.724138\n",
       "0       Ada Boost Classifier    0.320199   0.057693         0.363636\n",
       "1  Gradient Boost Classifier    0.542337   0.126316         0.714286\n",
       "2             XGB Classifier    0.554471   0.125104         0.772727"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_model = pd.concat([cv_result,boost_summary], axis=0)\n",
    "resume_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       572\n",
      "           1       0.82      0.14      0.24       100\n",
      "\n",
      "    accuracy                           0.87       672\n",
      "   macro avg       0.85      0.57      0.58       672\n",
      "weighted avg       0.86      0.87      0.83       672\n",
      "\n",
      "[[569   3]\n",
      " [ 86  14]]\n"
     ]
    }
   ],
   "source": [
    "#cek confusion matrix dr model Logreg\n",
    "logreg_pipe.fit(X_train, y_train)\n",
    "ypred=logreg_pipe.predict(X_test)\n",
    "print(classification_report(y_test,ypred))\n",
    "print(metrics.confusion_matrix(y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:15:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.93       572\n",
      "           1       0.77      0.17      0.28       100\n",
      "\n",
      "    accuracy                           0.87       672\n",
      "   macro avg       0.82      0.58      0.60       672\n",
      "weighted avg       0.86      0.87      0.83       672\n",
      "\n",
      "[[567   5]\n",
      " [ 83  17]]\n"
     ]
    }
   ],
   "source": [
    "#cek confusion matrix dr model XGB boost(terbaik kedua)\n",
    "pipe_XGB.fit(X_train, y_train)\n",
    "ypred=pipe_XGB.predict(X_test)\n",
    "print(classification_report(y_test,ypred))\n",
    "print(metrics.confusion_matrix(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Berdasarkan resume diatas maka akan digunakan Logistic Regresi, karena memiliki nilai precision tertinggi dan nilai precision antara kelas 1 dan 0 tidak beda jauh. kemudian akan lanjut ke proses hyperparameter tunning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tunning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression()\n",
    "\n",
    "estimator = Pipeline([\n",
    "    ('transformer', transformer),\n",
    "    ('model', logreg)\n",
    "])\n",
    "\n",
    "hyperparam_space =  {\n",
    "    'model__C': [100, 10, 1, 0.1, 0.01, 0.001],\n",
    "    'model__solver': ['liblinear', 'newton-cg']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "                estimator,\n",
    "                param_grid = hyperparam_space,\n",
    "                cv = StratifiedKFold(n_splits = 5),\n",
    "                scoring = 'precision',\n",
    "                n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('transformer',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('impute',\n",
       "                                                                         Pipeline(steps=[('impute',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('scaling',\n",
       "                                                                                          RobustScaler())]),\n",
       "                                                                         ['Income']),\n",
       "                                                                        ('encoder',\n",
       "                                                                         OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                         ['Education',\n",
       "                                                                          'Marital_Status']),\n",
       "                                                                        ('binary',\n",
       "                                                                         BinaryEncoder(),\n",
       "                                                                         ['Country']),\n",
       "                                                                        ('scale',\n",
       "                                                                         RobustScaler(),\n",
       "                                                                         ['Customer_Age',\n",
       "                                                                          'Recency'])])),\n",
       "                                       ('model', LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__C': [100, 10, 1, 0.1, 0.01, 0.001],\n",
       "                         'model__solver': ['liblinear', 'newton-cg']},\n",
       "             scoring='precision')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.599047619047619\n",
      "best param {'model__C': 0.1, 'model__solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "print('best score', grid_search.best_score_)\n",
    "print('best param', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Before</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression After</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       method     score\n",
       "0  Logistic Regression Before  0.823529\n",
       "1   Logistic Regression After  0.666667"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pipe.fit(X_train, y_train)\n",
    "y_pred_estimator = logreg_pipe.predict(X_test)\n",
    "precision_estimator = precision_score(y_test, y_pred_estimator)\n",
    "\n",
    "grid_search.best_estimator_.fit(X_train, y_train)\n",
    "y_pred_grid = grid_search.best_estimator_.predict(X_test)\n",
    "precision_best_estimator = precision_score(y_test, y_pred_grid)\n",
    "\n",
    "score_list = [precision_estimator, precision_best_estimator]\n",
    "method_name = ['Logistic Regression Before', 'Logistic Regression After']\n",
    "best_summary = pd.DataFrame({\n",
    "    'method': method_name,\n",
    "    'score': score_list\n",
    "})\n",
    "best_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nilai precision score sebelum dan sesudah tunning lebih baik sebelum tunning, sehingga akan diambil model tanpa tunning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing= data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Education', 'Marital_Status', 'Income', 'Kidhome', 'Teenhome',\n",
       "       'Recency', 'Response', 'Country', 'Customer_Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketing.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketing.to_csv('marketing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=marketing.drop(['Response'],axis=1)\n",
    "y=marketing['Response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,stratify=y,test_size=0.3,random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LogisticRegression()\n",
    "\n",
    "mean_scale = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy = 'mean')),\n",
    "    ('scaling', RobustScaler()),\n",
    "])\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('impute',mean_scale,['Income']),\n",
    "    ('encoder',OneHotEncoder(handle_unknown='ignore'),['Education','Marital_Status']),\n",
    "    ('binary',ce.BinaryEncoder(),['Country']),\n",
    "    ('scale',RobustScaler(),['Customer_Age','Recency'])\n",
    "],remainder='passthrough')\n",
    "\n",
    "\n",
    "model_final = Pipeline([\n",
    "    ('transformer',transformer),\n",
    "    ('model', model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8235294117647058\n"
     ]
    }
   ],
   "source": [
    "model_final.fit(X_train, y_train)\n",
    "y_pred_estimator = model_final.predict(X_test)\n",
    "print(precision_score(y_test, y_pred_estimator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.fit(X,y) #Final model, fit ke X dan y untuk memaksimalkan jumlh data yg diplajari oleh model\n",
    "\n",
    "#with pickle\n",
    "file_name='Model Final.sav'\n",
    "pickle.dump(model_final,open(file_name,'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict with Saved Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(file_name,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Education       2240 non-null   object \n",
      " 1   Marital_Status  2240 non-null   object \n",
      " 2   Income          2216 non-null   float64\n",
      " 3   Kidhome         2240 non-null   int64  \n",
      " 4   Teenhome        2240 non-null   int64  \n",
      " 5   Recency         2240 non-null   int64  \n",
      " 6   Country         2240 non-null   object \n",
      " 7   Customer_Age    2240 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(3)\n",
      "memory usage: 140.1+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict=pd.DataFrame({\n",
    "    'Education':['Master'],\n",
    "    'Marital_Status':['Single'],\n",
    "    'Income':[21888],\n",
    "    'Kidhome':[1],\n",
    "    'Teenhome':[0],\n",
    "    'Recency':[15],\n",
    "    'Country':['ME'],\n",
    "    'Customer_Age':[30]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46744927, 0.53255073]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_proba(df_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SP', 'CA', 'US', 'AUS', 'GER', 'IND', 'SA', 'ME'], dtype=object)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
